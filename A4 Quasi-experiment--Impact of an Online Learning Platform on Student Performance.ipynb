{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of an Online Learning Platform on Student Performance\n",
    "\n",
    "### Quasi-experiment\n",
    "\n",
    "### Project Idea: \n",
    "Examine the impact of a new online learning platform on student performance using data on student demographics, prior academic performance, and outcomes.\n",
    "\n",
    "### Methodology: \n",
    "Generate data for student attributes and outcomes. Utilize Nearest Neighbor matching to pair treated students with control students. Calculate mean differences for each feature between treated and control groups. Analyze mean outcomes and estimate the Average Treatment Effect (ATE) of the online learning platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data set\n",
    "\n",
    "This code will generate a synthetic dataset containing information about student demographics, prior academic performance, and final exam scores. You can modify the parameters and distributions as needed to better reflect your specific research context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student_ID  Gender  Age Ethnicity Socioeconomic_Status  High_School_GPA  \\\n",
      "0           1    Male   23     Black                  Low         2.127282   \n",
      "1           2  Female   24     Black               Medium         3.662747   \n",
      "2           3    Male   18     White                 High         3.197957   \n",
      "3           4    Male   18  Hispanic                 High         2.229866   \n",
      "4           5    Male   18  Hispanic               Medium         2.187715   \n",
      "\n",
      "   SAT_Score  Final_Exam_Score  \n",
      "0       1153                81  \n",
      "1       1298                91  \n",
      "2        940                67  \n",
      "3       1557                64  \n",
      "4        892                89  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of students\n",
    "n_students = 1000\n",
    "\n",
    "# Generate student demographics\n",
    "demographics = pd.DataFrame({\n",
    "    'Student_ID': range(1, n_students + 1),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], size=n_students),\n",
    "    'Age': np.random.randint(18, 25, size=n_students),\n",
    "    'Ethnicity': np.random.choice(['White', 'Black', 'Hispanic', 'Asian'], size=n_students),\n",
    "    'Socioeconomic_Status': np.random.choice(['Low', 'Medium', 'High'], size=n_students)\n",
    "})\n",
    "\n",
    "# Generate prior academic performance\n",
    "prior_performance = pd.DataFrame({\n",
    "    'Student_ID': range(1, n_students + 1),\n",
    "    'High_School_GPA': np.random.uniform(2.0, 4.0, size=n_students),\n",
    "    'SAT_Score': np.random.randint(800, 1600, size=n_students)\n",
    "})\n",
    "\n",
    "# Generate outcomes (e.g., exam scores)\n",
    "outcomes = pd.DataFrame({\n",
    "    'Student_ID': range(1, n_students + 1),\n",
    "    'Final_Exam_Score': np.random.randint(50, 100, size=n_students)\n",
    "})\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.merge(demographics, prior_performance, on='Student_ID')\n",
    "data = pd.merge(data, outcomes, on='Student_ID')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>High_School_GPA</th>\n",
       "      <th>SAT_Score</th>\n",
       "      <th>Final_Exam_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>21.005000</td>\n",
       "      <td>2.986954</td>\n",
       "      <td>1203.41200</td>\n",
       "      <td>74.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>2.040377</td>\n",
       "      <td>0.576381</td>\n",
       "      <td>230.07113</td>\n",
       "      <td>14.218453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000023</td>\n",
       "      <td>800.00000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.516871</td>\n",
       "      <td>1005.75000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.983421</td>\n",
       "      <td>1203.50000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.473738</td>\n",
       "      <td>1405.25000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.995642</td>\n",
       "      <td>1599.00000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Student_ID          Age  High_School_GPA   SAT_Score  Final_Exam_Score\n",
       "count  1000.000000  1000.000000      1000.000000  1000.00000       1000.000000\n",
       "mean    500.500000    21.005000         2.986954  1203.41200         74.819000\n",
       "std     288.819436     2.040377         0.576381   230.07113         14.218453\n",
       "min       1.000000    18.000000         2.000023   800.00000         50.000000\n",
       "25%     250.750000    19.000000         2.516871  1005.75000         63.000000\n",
       "50%     500.500000    21.000000         2.983421  1203.50000         74.000000\n",
       "75%     750.250000    23.000000         3.473738  1405.25000         88.000000\n",
       "max    1000.000000    24.000000         3.995642  1599.00000         99.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our synthetic dataset, we can proceed with implementing the nearest neighbor matching approach to investigate the impact of the new online learning platform on student performance.\n",
    "\n",
    "Here's an outline of the next steps:\n",
    "1.\tPreprocess the data: Ensure that the dataset is prepared for matching by encoding categorical variables and scaling numerical variables if necessary.\n",
    "2.\tImplement nearest neighbor matching: Use the sklearn.neighbors.NearestNeighbors class to identify nearest neighbors for each treated student based on their covariates.\n",
    "3.\tPerform matching: Match treated students with control students based on nearest neighbors.\n",
    "4.\tAssess balance: Evaluate the balance of covariates between the treated and control groups to ensure that they are comparable after matching.\n",
    "5.\tAnalyze outcomes: Compare the outcomes (e.g., final exam scores) between the matched treated and control groups to estimate the impact of the new online learning platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "\n",
    "Let's start by preprocessing the data to ensure that it's ready for matching. We'll encode categorical variables and scale numerical variables.\n",
    "\n",
    "This code snippet preprocesses the dataset by scaling numerical features and encoding categorical features. After preprocessing, we'll have a feature matrix X and a target vector y, which are ready for matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97824975 -1.49224731 -0.21922448 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.4686005   1.17306397  0.41133075 ...  0.          0.\n",
      "   1.        ]\n",
      " [-1.47350401  0.36626609 -1.14548837 ...  1.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.00245175  0.70458447 -1.74125435 ...  1.          1.\n",
      "   0.        ]\n",
      " [ 1.4686005   0.72442951 -1.3542239  ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.47350401 -1.11712338 -1.73255704 ...  0.          1.\n",
      "   0.        ]]\n",
      "[81 91 67 64 89 81 58 86 59 69 55 97 52 91 60 92 66 81 53 53 66 90 68 54\n",
      " 81 71 55 84 71 50 69 71 97 60 62 91 52 58 61 72 63 82 67 98 90 58 72 59\n",
      " 68 96 54 96 72 79 74 77 83 94 97 96 74 59 63 91 95 79 90 74 63 84 97 83\n",
      " 59 84 60 60 70 70 71 94 56 66 51 61 91 67 60 65 98 67 84 75 65 55 93 92\n",
      " 96 96 97 91 61 62 53 88 51 75 76 76 64 57 56 96 95 89 61 62 92 66 66 85\n",
      " 70 57 54 75 65 85 77 78 96 61 86 79 72 65 63 59 56 94 86 78 52 64 85 96\n",
      " 95 68 62 91 70 86 76 78 69 74 55 85 51 71 81 65 67 54 85 79 94 68 72 83\n",
      " 62 92 78 85 71 96 85 58 88 68 87 55 96 64 69 58 81 53 99 67 54 69 72 60\n",
      " 86 71 53 78 93 83 62 91 58 91 80 56 53 68 91 79 80 84 70 80 68 80 81 51\n",
      " 59 51 51 73 66 81 65 65 95 88 80 92 73 50 60 70 53 56 75 96 99 61 80 66\n",
      " 82 60 77 81 50 96 77 91 56 51 91 73 53 93 68 75 60 89 99 92 60 94 52 61\n",
      " 52 91 76 98 51 98 65 51 79 69 87 77 74 81 59 91 89 82 62 90 91 96 86 65\n",
      " 94 71 69 99 92 76 90 65 83 81 75 74 51 61 89 58 61 75 58 59 81 83 97 69\n",
      " 88 51 50 85 73 76 51 80 63 51 78 64 61 86 77 69 88 73 70 59 95 63 86 67\n",
      " 73 63 83 61 71 55 85 94 85 71 63 65 85 74 81 82 94 85 69 67 87 52 72 81\n",
      " 94 65 54 53 70 89 63 88 80 63 55 61 65 66 94 72 63 56 95 81 64 93 66 90\n",
      " 96 93 83 54 94 76 72 89 63 64 92 82 80 84 66 77 68 95 72 81 89 62 69 84\n",
      " 54 58 78 55 74 80 71 51 94 54 76 74 57 50 69 93 72 81 60 88 96 73 60 78\n",
      " 75 65 84 69 95 52 50 96 50 66 51 78 69 55 57 78 97 82 52 84 54 76 93 61\n",
      " 69 94 69 58 88 53 68 87 76 94 92 62 62 71 77 96 94 71 92 68 57 57 91 75\n",
      " 97 75 72 92 62 77 58 69 68 97 88 61 64 80 63 60 75 91 76 60 87 83 92 68\n",
      " 55 95 87 98 91 77 50 84 89 57 96 56 60 88 53 74 61 75 87 95 61 92 86 95\n",
      " 73 65 62 74 53 60 81 98 56 95 60 77 90 72 94 72 99 77 92 96 75 74 78 68\n",
      " 82 85 63 63 84 79 77 66 52 65 95 79 78 94 64 95 74 87 91 96 87 72 74 91\n",
      " 56 71 66 67 98 90 59 59 56 97 99 87 76 82 50 93 83 53 66 53 92 75 53 50\n",
      " 56 79 99 58 84 57 73 68 85 99 92 76 81 63 67 77 78 65 84 96 80 53 86 66\n",
      " 88 97 95 75 97 88 90 53 79 79 71 60 51 93 61 79 85 67 75 56 50 75 72 75\n",
      " 94 55 55 93 57 73 71 68 86 67 80 86 79 91 82 59 86 61 79 76 88 58 70 61\n",
      " 78 82 92 64 51 88 93 67 52 56 92 67 93 87 86 82 93 80 60 53 67 53 98 83\n",
      " 78 73 71 51 93 55 91 74 70 65 80 63 88 77 81 77 98 58 94 71 81 54 72 54\n",
      " 91 81 59 88 64 56 78 96 52 68 59 77 78 64 84 55 61 96 87 62 78 68 52 57\n",
      " 57 69 96 53 70 52 94 57 72 65 62 52 97 58 63 62 56 64 56 87 83 90 71 73\n",
      " 98 86 93 50 59 92 65 95 57 98 74 99 61 74 66 75 95 97 63 90 85 72 92 55\n",
      " 96 54 92 74 67 62 92 63 77 67 77 76 81 96 58 89 81 69 77 82 53 95 83 97\n",
      " 52 75 57 55 65 73 97 88 79 94 62 54 74 69 67 96 67 51 59 94 99 96 61 96\n",
      " 62 99 96 60 68 84 88 75 95 63 94 93 73 90 50 92 71 72 68 67 61 77 77 82\n",
      " 68 77 98 86 75 84 83 84 89 65 87 62 72 71 65 77 97 84 94 95 57 93 71 70\n",
      " 75 89 70 74 90 50 55 72 72 92 92 72 81 79 62 92 67 72 64 82 70 88 72 76\n",
      " 94 93 67 73 96 89 91 56 99 97 69 76 55 76 58 94 80 70 75 89 97 94 62 98\n",
      " 72 69 86 77 66 77 90 51 74 99 90 55 60 87 55 94 60 63 51 89 52 84 82 73\n",
      " 68 67 98 73 94 84 50 85 74 94 98 92 83 74 65 83 78 68 72 68 74 65 58 50\n",
      " 91 68 82 83 65 93 89 67 83 74 94 55 70 55 81 90]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['Age', 'High_School_GPA', 'SAT_Score']\n",
    "categorical_features = ['Gender', 'Ethnicity', 'Socioeconomic_Status']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing pipeline to the data\n",
    "X = preprocessor.fit_transform(data.drop(columns=['Student_ID', 'Final_Exam_Score']))\n",
    "y = data['Final_Exam_Score'].values\n",
    "\n",
    "# Display the preprocessed feature matrix and target vector\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors:\n",
    "\n",
    "Now that we have preprocessed the data, we can proceed with implementing nearest neighbor matching to match treated students with control students based on their covariates.\n",
    "\n",
    "We'll use the sklearn.neighbors.NearestNeighbors class to find the nearest neighbors for each treated student. Then, we'll use these nearest neighbors to perform matching.\n",
    "\n",
    "Here's how we can implement nearest neighbor matching:\n",
    "\n",
    "In this code:\n",
    "•\tWe specify the number of nearest neighbors (n_neighbors) to consider for matching. Each treated student will be matched with their nearest neighbor.\n",
    "•\tWe initialize a NearestNeighbors object and fit it to the preprocessed data (X).\n",
    "•\tWe use the kneighbors method to find the nearest neighbors for each treated student (X[:n_students]). The indices variable will contain the indices of the nearest neighbors for each treated student.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Number of nearest neighbors to consider for matching\n",
    "n_neighbors = 1  # Each treated student will be matched with their nearest neighbor\n",
    "\n",
    "# Initialize NearestNeighbors object\n",
    "nn = NearestNeighbors(n_neighbors=n_neighbors + 1)  # Include itself in the neighbors\n",
    "\n",
    "# Fit NearestNeighbors model to the preprocessed data\n",
    "nn.fit(X)\n",
    "\n",
    "# Find nearest neighbors for treated students\n",
    "distances, indices = nn.kneighbors(X[:n_students], n_neighbors=n_neighbors + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching\n",
    "\n",
    "Now that we have identified the nearest neighbors for each treated student, we can proceed with performing matching in the next step.\n",
    "\n",
    "Now that we have identified the nearest neighbors for each treated student, we can proceed with performing matching.\n",
    "For each treated student, we will match them with their nearest neighbor from the control group. We'll create matched pairs of treated and control students based on these nearest neighbors.\n",
    "\n",
    "Here's how we can perform matching:\n",
    "\n",
    "In this code:\n",
    "•\tWe initialize lists to store the indices of matched treated and control students.\n",
    "•\tWe loop through the indices of treated students and their nearest neighbors from the control group, and add them to the corresponding lists.\n",
    "•\tWe extract the features and outcomes for the matched treated and control students.\n",
    "•\tWe print the indices of matched treated and control students for verification.\n",
    "After performing matching, we'll have matched pairs of treated and control students, ready for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of matched treated students: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "Indices of matched control students: [969, 106, 331, 550, 200, 236, 799, 912, 488, 76, 194, 177, 337, 491, 695, 362, 543, 182, 393, 576, 126, 268, 201, 783, 237, 173, 582, 736, 396, 164, 890, 965, 558, 612, 230, 716, 919, 298, 819, 482, 795, 286, 860, 366, 424, 913, 872, 941, 103, 575, 873, 987, 966, 404, 546, 782, 938, 843, 472, 664, 316, 655, 298, 291, 121, 849, 267, 632, 642, 686, 357, 707, 326, 130, 886, 164, 9, 140, 710, 65, 809, 977, 785, 224, 440, 151, 520, 889, 659, 117, 91, 90, 230, 527, 372, 481, 175, 694, 625, 600, 498, 603, 863, 48, 299, 408, 1, 296, 490, 735, 835, 852, 195, 460, 633, 449, 209, 89, 370, 636, 651, 64, 790, 505, 384, 639, 20, 949, 864, 677, 401, 158, 532, 730, 349, 415, 344, 247, 467, 459, 77, 684, 676, 142, 378, 966, 816, 321, 260, 877, 926, 85, 498, 459, 244, 915, 63, 174, 426, 580, 63, 925, 555, 189, 29, 416, 373, 610, 132, 749, 206, 812, 854, 25, 157, 96, 885, 11, 807, 181, 811, 179, 17, 131, 313, 58, 511, 482, 135, 529, 302, 748, 198, 668, 10, 112, 545, 335, 213, 247, 4, 22, 861, 301, 916, 882, 444, 234, 354, 116, 724, 933, 738, 198, 40, 845, 208, 297, 104, 832, 873, 744, 741, 503, 83, 236, 179, 992, 546, 542, 34, 754, 659, 284, 207, 450, 225, 24, 301, 487, 324, 646, 595, 903, 154, 420, 891, 137, 454, 327, 208, 910, 545, 944, 136, 489, 413, 991, 804, 740, 856, 266, 488, 780, 911, 621, 940, 985, 21, 78, 970, 324, 887, 655, 562, 469, 605, 45, 123, 405, 934, 28, 462, 58, 233, 135, 728, 155, 592, 711, 776, 63, 830, 862, 9, 408, 107, 217, 62, 104, 587, 203, 190, 918, 447, 807, 670, 375, 928, 323, 939, 789, 677, 184, 415, 323, 60, 501, 723, 320, 319, 147, 902, 309, 240, 813, 521, 249, 451, 793, 850, 2, 433, 168, 881, 197, 802, 12, 173, 897, 811, 793, 875, 680, 67, 626, 359, 66, 654, 134, 689, 425, 794, 936, 208, 873, 718, 986, 873, 491, 827, 792, 15, 774, 100, 264, 43, 708, 610, 696, 118, 547, 951, 774, 727, 307, 409, 737, 101, 743, 501, 773, 551, 629, 630, 485, 482, 668, 413, 359, 428, 278, 833, 18, 63, 858, 28, 967, 971, 368, 739, 130, 276, 724, 648, 582, 588, 982, 295, 77, 878, 833, 599, 388, 995, 135, 165, 551, 997, 750, 245, 808, 240, 587, 44, 351, 158, 814, 390, 936, 652, 752, 964, 381, 324, 720, 308, 689, 746, 748, 84, 584, 891, 874, 206, 645, 725, 304, 682, 115, 235, 328, 813, 508, 670, 484, 513, 841, 870, 960, 113, 501, 230, 467, 98, 523, 451, 138, 534, 275, 959, 614, 834, 686, 643, 719, 624, 115, 504, 644, 524, 95, 39, 620, 563, 936, 145, 239, 8, 255, 607, 13, 8, 539, 771, 618, 521, 976, 500, 679, 498, 461, 133, 223, 800, 123, 654, 132, 667, 894, 840, 186, 184, 456, 677, 52, 231, 419, 977, 717, 783, 496, 974, 646, 480, 779, 489, 93, 846, 189, 178, 822, 132, 744, 656, 565, 967, 720, 795, 493, 624, 888, 229, 16, 600, 557, 228, 371, 373, 834, 3, 417, 733, 990, 333, 162, 519, 545, 32, 991, 293, 316, 274, 484, 714, 535, 742, 918, 253, 246, 350, 581, 971, 441, 780, 788, 19, 905, 673, 556, 159, 571, 405, 990, 441, 726, 867, 423, 406, 21, 830, 872, 288, 948, 631, 242, 839, 856, 558, 948, 99, 962, 755, 101, 817, 219, 848, 490, 120, 994, 368, 804, 33, 990, 580, 478, 830, 397, 532, 430, 483, 265, 35, 627, 476, 98, 345, 623, 770, 383, 384, 594, 67, 150, 980, 711, 868, 57, 978, 125, 984, 846, 720, 474, 479, 798, 241, 855, 404, 933, 996, 120, 853, 496, 693, 61, 534, 899, 593, 232, 607, 820, 747, 714, 581, 572, 720, 508, 387, 924, 454, 649, 864, 578, 623, 757, 142, 312, 45, 499, 343, 932, 448, 793, 141, 838, 69, 705, 141, 350, 958, 805, 30, 654, 113, 700, 907, 411, 733, 482, 17, 993, 766, 306, 472, 687, 32, 71, 367, 452, 78, 635, 941, 417, 564, 577, 35, 519, 942, 475, 666, 158, 945, 318, 210, 446, 585, 135, 286, 980, 133, 50, 866, 698, 992, 109, 27, 251, 889, 400, 259, 222, 566, 379, 533, 475, 879, 779, 439, 169, 419, 160, 940, 16, 231, 602, 182, 675, 799, 472, 281, 927, 890, 601, 810, 168, 702, 827, 666, 668, 628, 494, 952, 381, 373, 828, 290, 947, 427, 747, 574, 904, 32, 23, 913, 297, 879, 927, 575, 311, 122, 75, 361, 683, 352, 40, 416, 925, 912, 6, 504, 182, 336, 317, 258, 691, 91, 178, 421, 428, 764, 180, 171, 325, 427, 831, 810, 604, 919, 999, 661, 869, 531, 8, 768, 838, 898, 767, 775, 847, 292, 815, 219, 411, 472, 110, 908, 99, 685, 290, 510, 457, 576, 57, 72, 215, 528, 979, 606, 741, 330, 987, 111, 652, 172, 179, 260, 899, 970, 771, 753, 202, 293, 102, 672, 966, 732, 586, 636, 679, 458, 881, 46, 50, 443, 342, 320, 149, 410, 746, 810, 871, 205, 680, 528, 176, 74, 272, 541, 87, 30, 246, 930, 851, 994, 545, 310, 339, 826, 857, 681, 329, 322, 243, 781, 577, 863, 696, 836, 343, 251, 264, 7, 45, 25, 976, 204, 94, 567, 36, 459, 735, 743, 510, 669, 161, 150, 761, 308, 725, 892, 508, 681, 211, 976, 248, 429, 461, 56, 310, 266, 712, 718, 322, 253, 133, 959, 777, 599, 127, 58, 372, 772, 117, 880, 168, 204, 78, 206, 946, 459, 675, 90, 972, 432, 31, 865, 397, 480, 937, 858, 572, 963, 148, 522, 827, 934, 81, 638, 847, 634, 115, 407, 899, 640, 267, 357, 851, 947, 419, 553, 257, 227, 701, 894, 789, 650, 93, 108, 819]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store matched pairs\n",
    "matched_treated_indices = []\n",
    "matched_control_indices = []\n",
    "\n",
    "# Match treated students with their nearest neighbor from the control group\n",
    "for treated_index, control_index in zip(range(n_students), indices[:, 1:]):\n",
    "    matched_treated_indices.append(treated_index)\n",
    "    matched_control_indices.append(control_index[0])\n",
    "\n",
    "# Extract matched features and outcomes\n",
    "matched_X_treated = X[matched_treated_indices]\n",
    "matched_X_control = X[matched_control_indices]\n",
    "matched_y_treated = y[matched_treated_indices]\n",
    "matched_y_control = y[matched_control_indices]\n",
    "\n",
    "# Display the indices of matched treated and control students\n",
    "print(\"Indices of matched treated students:\", matched_treated_indices)\n",
    "print(\"Indices of matched control students:\", matched_control_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Balance:\n",
    "\n",
    "Now that we have matched treated and control students, we need to assess the balance of covariates between the matched groups to ensure that they are comparable. This step is crucial to ensure that any differences in outcomes between the treated and control groups can be attributed to the treatment effect rather than confounding variables.\n",
    "\n",
    "We can assess balance by comparing the distributions of covariates between the treated and control groups. Commonly used metrics include standardized mean differences (SMDs) and visual inspection of histograms or density plots.\n",
    "\n",
    "Here's how we can assess balance using standardized mean differences:\n",
    "\n",
    "In this code:\n",
    "•\tWe calculate the standardized mean differences separately for numerical and categorical features.\n",
    "•\tFor numerical features, we iterate through preprocessor.transformers_[0][2].\n",
    "•\tFor categorical features, we iterate through preprocessor.named_transformers_['cat'].get_feature_names_out() and add the index offset cat_features_idx_start.\n",
    "•\tWe concatenate the lists of standardized mean differences for numerical and categorical features.\n",
    "•\tWe print the standardized mean differences for each covariate along with their respective feature names.\n",
    "\n",
    "This should allow you to calculate the standardized mean differences for both numerical and categorical features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized mean differences\n",
    "def standardized_mean_difference(group1, group2):\n",
    "    \"\"\"Calculate the standardized mean difference between two groups.\"\"\"\n",
    "    diff = np.mean(group1) - np.mean(group2)\n",
    "    pooled_std = np.sqrt((np.var(group1) + np.var(group2)) / 2)\n",
    "    return diff / pooled_std\n",
    "\n",
    "# Calculate standardized mean differences for numerical features\n",
    "smds_numerical = []\n",
    "for feature_idx, feature_name in enumerate(preprocessor.transformers_[0][2]):\n",
    "    smd = standardized_mean_difference(matched_X_treated[:, feature_idx], matched_X_control[:, feature_idx])\n",
    "    smds_numerical.append(smd)\n",
    "\n",
    "# Calculate standardized mean differences for categorical features\n",
    "smds_categorical = []\n",
    "cat_features_idx_start = len(preprocessor.transformers_[0][2])\n",
    "for feature_idx, feature_name in enumerate(preprocessor.named_transformers_['cat'].get_feature_names_out()):\n",
    "    smd = standardized_mean_difference(matched_X_treated[:, cat_features_idx_start + feature_idx], matched_X_control[:, cat_features_idx_start + feature_idx])\n",
    "    smds_categorical.append(smd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the standardized mean differences, we can inspect them to determine whether balance has been achieved. A standardized mean difference below 0.1 is generally considered indicative of good balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized mean difference for Age: -0.0009885783299738143\n",
      "Standardized mean difference for High_School_GPA: -0.011039412870220177\n",
      "Standardized mean difference for SAT_Score: 0.003567050344670093\n",
      "Standardized mean difference for Gender_Male: -0.00200036209831266\n",
      "Standardized mean difference for Ethnicity_Black: 0.0022869856430335796\n",
      "Standardized mean difference for Ethnicity_Hispanic: -0.0023567640287536166\n",
      "Standardized mean difference for Ethnicity_White: -0.0022755646821052775\n",
      "Standardized mean difference for Socioeconomic_Status_Low: -0.006349074822465663\n",
      "Standardized mean difference for Socioeconomic_Status_Medium: -0.0021000642261963134\n"
     ]
    }
   ],
   "source": [
    "# Display standardized mean differences for each covariate\n",
    "for feature_name, smd in zip(preprocessor.transformers_[0][2] + list(preprocessor.named_transformers_['cat'].get_feature_names_out()), smds_numerical + smds_categorical):\n",
    "    print(f\"Standardized mean difference for {feature_name}: {smd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the SMDs:\n",
    "\n",
    "•\tSMD close to 0 indicates good balance between the matched treated and control groups for that covariate.\n",
    "•\tSMD greater than 0.1 may suggest potential imbalance, and further investigation is needed.\n",
    "•\tSMD less than -0.1 may also suggest potential imbalance, and further investigation is needed.\n",
    "Based on the calculated SMDs you provided:\n",
    "1.\tAge: SMD is close to 0 (-0.00099), indicating good balance.\n",
    "2.\tHigh_School_GPA: SMD is close to 0 (-0.011), indicating good balance.\n",
    "3.\tSAT_Score: SMD is close to 0 (0.00357), indicating good balance.\n",
    "4.\tGender_Male: SMD is close to 0 (-0.002), indicating good balance.\n",
    "5.\tEthnicity_Black: SMD is close to 0 (0.00229), indicating good balance.\n",
    "6.\tEthnicity_Hispanic: SMD is close to 0 (-0.00236), indicating good balance.\n",
    "7.\tEthnicity_White: SMD is close to 0 (-0.00228), indicating good balance.\n",
    "8.\tSocioeconomic_Status_Low: SMD is close to 0 (-0.00635), indicating good balance.\n",
    "9.\tSocioeconomic_Status_Medium: SMD is close to 0 (-0.0021), indicating good balance.\n",
    "\n",
    "Overall, based on the SMDs calculated, it appears that there is good balance between the matched treated and control groups for all covariates. This suggests that the matching process has effectively balanced the distribution of covariates between the two groups, reducing the potential for confounding bias in estimating treatment effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the treatment effect\n",
    "\n",
    "Now that we have assessed the balance between the matched treated and control groups, we can proceed with analyzing outcomes to estimate the treatment effect.\n",
    "\n",
    "To do this, we'll compare the outcomes (dependent variable) between the matched treated and control groups. Commonly used methods for estimating treatment effects include calculating the average treatment effect (ATE), average treatment effect on the treated (ATT), or conducting hypothesis tests.\n",
    "\n",
    "Here's how we can proceed with analyzing outcomes:\n",
    "\n",
    "In this code:\n",
    "•\tWe calculate the mean outcome for the matched treated and control groups using np.mean().\n",
    "•\tWe calculate the treatment effect as the difference between the mean outcome for the treated group and the mean outcome for the control group.\n",
    "•\tWe print the mean outcomes and the calculated treatment effect.\n",
    "\n",
    "After running this code, we'll have the mean outcomes for both the treated and control groups, as well as the calculated treatment effect. This will provide us with valuable insights into the impact of the treatment on the outcome variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean outcome for treated group: 74.819\n",
      "Mean outcome for control group: 74.795\n",
      "Average Treatment Effect (ATE): 0.02400000000000091\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean outcome for the matched treated and control groups\n",
    "mean_outcome_treated = np.mean(matched_y_treated)\n",
    "mean_outcome_control = np.mean(matched_y_control)\n",
    "\n",
    "# Calculate the treatment effect (ATE)\n",
    "ate = mean_outcome_treated - mean_outcome_control\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean outcome for treated group:\", mean_outcome_treated)\n",
    "print(\"Mean outcome for control group:\", mean_outcome_control)\n",
    "print(\"Average Treatment Effect (ATE):\", ate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the mean outcomes for the treated and control groups, and the calculated Average Treatment Effect (ATE) of approximately 0.024, we can draw several insights into the impact of the treatment on the outcome variable:\n",
    "1.\tSmall Treatment Effect: The ATE of 0.024 indicates a small positive effect of the treatment on the outcome variable. While this effect may be statistically significant, its practical significance depends on the context of the study and the scale of the outcome variable.\n",
    "2.\tSimilar Mean Outcomes: The mean outcome for the treated group (74.819) is slightly higher than that of the control group (74.795), suggesting a positive treatment effect. However, the difference in means is relatively small, indicating a subtle impact of the treatment.\n",
    "3.\tPotential Practical Significance: While the treatment effect is small in magnitude, it may still have practical significance depending on the context. Further analysis and consideration of the context of the study are needed to determine the practical implications of this effect.\n",
    "\n",
    "Additional analyses to explore could include:\n",
    "•\tSubgroup Analysis: Investigate whether the treatment effect varies across different subgroups of the population. This can help identify any differential effects of the treatment based on demographic or other characteristics.\n",
    "•\tSensitivity Analysis: Perform sensitivity analysis to assess the robustness of the treatment effect estimate to different modeling assumptions or methodological choices. This can enhance the credibility of the findings and provide insights into the stability of the results.\n",
    "•\tLongitudinal Analysis: If the data is longitudinal, consider analyzing the trajectory of outcomes over time to understand the dynamics of the treatment effect and its persistence or attenuation over time.\n",
    "•\tCausal Mediation Analysis: Explore potential mechanisms through which the treatment affects the outcome by conducting causal mediation analysis. This can help uncover the underlying pathways through which the treatment operates to produce its effects.\n",
    "\n",
    "These additional analyses can provide a deeper understanding of the treatment effect and its implications, helping to inform decision-making and further research efforts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
